# -*- coding: utf-8 -*-
"""Cross_Validation_Multiclass.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Den7XaIXGWZD_wPaxFkrZx9n4UKJLMmb
"""

# Commented out IPython magic to ensure Python compatibility.
# Binary Model Classification
import zipfile
import nibabel as nib
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.utils import make_grid
import numpy as np
import pandas as pd
import pickle
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import glob
from torch.autograd import Variable
from torchvision import models
from torch.nn import Module,  Linear, ReLU, CrossEntropyLoss, Sequential, Conv3d, MaxPool3d, Softmax
from torch.optim import Adam
from tqdm import tqdm
from sklearn.metrics import accuracy_score
import seaborn as sn
import torch.optim as optim
from sklearn.metrics import accuracy_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import matthews_corrcoef
from torchsummary import summary
from torch.utils.data import DataLoader, ConcatDataset
from sklearn.model_selection import KFold
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive/')

import os
#walk through directory and list through files
for dirpath, dirnames, filenames in os.walk("/content/drive/My Drive/ADNI_full"):
  print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")
len(filenames)

#Get the class names
import numpy as np
import pathlib
data_dir = pathlib.Path('/content/drive/My Drive/ADNI_full')
class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))
print(class_names)

with open("/content/drive/MyDrive/Images_ADNI.txt", 'rb') as fp:
  X=pickle.load(fp)
  y=pickle.load(fp)

X.shape, y.shape

X = torch.from_numpy(X)
X.shape, X.dtype

X=X.reshape(663,1,100,100,55)

X.shape

X=X.expand(-1,3,-1,-1,-1)
X.shape

y = torch.from_numpy(y)
y.shape, y.dtype

from sklearn.model_selection import train_test_split
#batch_size=32
X_train,X_test_data, y_train,y_test_data =train_test_split(X,y, test_size=0.2,  random_state=42)
X_val,X_test,y_val,y_test= train_test_split(X_test_data,y_test_data, test_size=0.5,random_state=42)
#X_train, X_test, y_train, y_test,X_val,y_val = X_train.cuda(), X_test.cuda(), y_train.cuda(), y_test.cuda(),X_val.cuda(), y_val.cuda()

(X_train.shape, y_train.shape),(X_test.shape, y_test.shape),(X_val.shape,y_val.shape), (X_train.dtype, y_train.dtype)

from torch.utils.data import DataLoader,TensorDataset
BATCH_SIZE = 10
dataset3 = TensorDataset(X_train, y_train)
dataset1= TensorDataset(X_val, y_val)

dataset = ConcatDataset([dataset3, dataset1])

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

multiclass_resnet_finetune = models.video.r3d_18(pretrained=True, progress=False)

multiclass_resnet_finetune = multiclass_resnet_finetune.to(device)

summary(multiclass_resnet_finetune, (3, 100, 100,55))

print(multiclass_resnet_finetune)

multiclass_resnet_finetune.layer4

for param in multiclass_resnet_finetune.layer4.parameters():
    param.requires_grad = False

multiclass_resnet_finetune.fc =  nn.Sequential(
            nn.Linear(512, 512),
            nn.LeakyReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(512, 3),
            )
for param in multiclass_resnet_finetune.fc.parameters():
    param.requires_grad = True

summary(multiclass_resnet_finetune, (3, 100, 100,55))

# Configuration options
k_folds = 3
num_epochs = 1
loss_function = nn.CrossEntropyLoss()
  
# For fold results
results = {}
  
# Set random number seed
torch.manual_seed(42)
kfold = KFold(n_splits=k_folds, shuffle=True)
    
# Start print
print('kfold')
# K-fold Cross Validation model evaluation
for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):
  # Print
  print(f'FOLD {fold}')
  # Sample elements randomly from a given list of ids, no replacement.
  train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)
  test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)
  
  trainloader = torch.utils.data.DataLoader(
                      dataset, 
                      batch_size=10, sampler=train_subsampler)
  testloader = torch.utils.data.DataLoader(
                      dataset,
                      batch_size=10, sampler=test_subsampler)
  # Initialize optimizer
  optimizer = torch.optim.Adam(multiclass_resnet_finetune.parameters(), lr=0.001)
    
  # Run the training loop for defined number of epochs
  for epoch in range(0, num_epochs):

    # Print epoch
    print(f'Starting epoch {epoch+1}')

    # Set current loss value
    current_loss = 0.0

    # Iterate over the DataLoader for training data
    for i, data in enumerate(trainloader, 0):
        
      # Get inputs
      inputs, targets = data
        
      # Zero the gradients
      optimizer.zero_grad()
        
      # Perform forward pass
      outputs = multiclass_resnet_finetune(inputs)
        
      # Compute loss
      loss = loss_function(outputs, targets)
        
      # Perform backward pass
      loss.backward()
        
      # Perform optimization
      optimizer.step()
        
      # Print statistics
      current_loss += loss.item()
      if i % 10 == 9:
          print('Loss after mini-batch %5d: %.3f' %
                  (i + 1, current_loss / 10))
          current_loss = 0.0
            
    # Process is complete.
    print('Training process has finished. Saving trained model.')

    # Print about testing
    print('Starting testing')
    
    # Saving the model
    save_path = f'./model-fold-{fold}.pth'
    model_scripted = torch.jit.script(multiclass_resnet_finetune) # Export to TorchScript
    model_scripted.save('model_scripted_multiclass.pth') 

    # Evaluation for this fold
    correct, total = 0, 0
    with torch.no_grad():

      # Iterate over the test data and generate predictions
      for i, data in enumerate(testloader, 0):

        # Get inputs
        inputs, targets = data

        # Generate outputs
        outputs = multiclass_resnet_finetune(inputs)

        # Set total and correct
        _, predicted = torch.max(outputs.data, 1)
        total += targets.size(0)
        correct += (predicted == targets).sum().item()

      # Print accuracy
      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))
      print('--------------------------------')
      results[fold] = 100.0 * (correct / total)
    
  # Print fold results
  print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')
  print('--------------------------------')
  sum = 0.0
  for key, value in results.items():
    print(f'Fold {key}: {value} %')
    sum += value
  print(f'Average: {sum/len(results.items())} %')

